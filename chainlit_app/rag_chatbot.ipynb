{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6ceA3o2eH8W"
   },
   "source": [
    "# RAG Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlsi7TEUZdDU"
   },
   "source": [
    " ## 1. Install some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxWI_q1qZB3j",
    "outputId": "3de621bd-1de3-44b3-b1e5-874a1fb582f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.41.2\n",
    "!pip install -q bitsandbytes==0.43.1\n",
    "!pip install -q accelerate==0.31.0\n",
    "!pip install -q langchain==0.2.5\n",
    "!pip install -q langchainhub==0.1.20\n",
    "!pip install -q langchain-chroma==0.1.1\n",
    "!pip install -q langchain-community==0.2.5\n",
    "!pip install -q langchain_huggingface==0.0.3\n",
    "!pip install -q python-dotenv==1.0.1\n",
    "!pip install -q pypdf==4.2.0\n",
    "!pip install -q numpy==1.24.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtlJYTcrZdwr"
   },
   "source": [
    " ## 2. Build vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvi3qzpIZYGq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain . chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTI0cOP5ZyrP"
   },
   "outputs": [],
   "source": [
    "# Read PDF file\n",
    "Loader = PyPDFLoader\n",
    "FILE_PATH = \"/content/YOLOv10_Tutorials.pdf\"\n",
    "loader = Loader(FILE_PATH)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grzzHcuTaICg",
    "outputId": "148b4e1b-015d-4824-f3c7-eafc16febc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sub-documents:  33\n",
      "page_content='AI VIET NAM \u2013 AI COURSE 2024\\nTutorial: Ph\u00e1t hi\u1ec7n \u0111\u1ed1i t\u01b0\u1ee3ng trong \u1ea3nh v\u1edbi\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui v\u00e0\\nQuang-Vinh Dinh\\nNg\u00e0y 20 th\u00e1ng 6 n\u0103m 2024\\nI. Gi\u1edbi thi\u1ec7u\\nObject Detection (T\u1ea1m d\u1ecbch: Ph\u00e1t hi\u1ec7n \u0111\u1ed1i t\u01b0\u1ee3ng) l\u00e0 m\u1ed9t b\u00e0i to\u00e1n c\u1ed5 \u0111i\u1ec3n thu\u1ed9c l\u0129nh v\u1ef1c\\nComputer Vision. M\u1ee5c ti\u00eau c\u1ee7a b\u00e0i to\u00e1n n\u00e0y l\u00e0 t\u1ef1 \u0111\u1ed9ng x\u00e1c \u0111\u1ecbnh v\u1ecb tr\u00ed c\u1ee7a c\u00e1c \u0111\u1ed1i t\u01b0\u1ee3ng trong\\nm\u1ed9t t\u1ea5m \u1ea3nh. T\u00ednh t\u1edbi th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i, \u0111\u00e3 c\u00f3 r\u1ea5t nhi\u1ec1u ph\u01b0\u01a1ng ph\u00e1p \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n nh\u1eb1m\\ngi\u1ea3i quy\u1ebft hi\u1ec7u qu\u1ea3 b\u00e0i to\u00e1n n\u00e0y. Trong \u0111\u00f3, c\u00e1c ph\u01b0\u01a1ng ph\u00e1p thu\u1ed9c h\u1ecd YOLO (You Only Look\\nOnce) thu h\u00fat \u0111\u01b0\u1ee3c s\u1ef1 ch\u00fa \u00fd r\u1ea5t l\u1edbn t\u1eeb c\u1ed9ng \u0111\u1ed3ng nghi\u00ean c\u1ee9u b\u1edfi \u0111\u1ed9 ch\u00ednh x\u00e1c v\u00e0 t\u1ed1c \u0111\u1ed9 th\u1ef1c\\nthi m\u00e0 lo\u1ea1i m\u00f4 h\u00ecnh n\u00e0y mang l\u1ea1i.\\nH\u00ecnh 1: Logo c\u1ee7a m\u00f4 h\u00ecnh YOLO. \u1ea2nh: link.\\nTh\u1eddi gian v\u1eeba qua, Ao Wang v\u00e0 c\u00e1c c\u1ed9ng s\u1ef1 t\u1ea1i \u0110\u1ea1i h\u1ecdc Thanh Hoa (Tsinghua University)\\n\u0111\u00e3 \u0111\u1ec1 xu\u1ea5t m\u00f4 h\u00ecnh YOLOv10 trong b\u00e0i b\u00e1o YOLOv10: Real-Time End-to-End Object\\nDetection [10]. V\u1edbi nh\u1eefng c\u1ea3i ti\u1ebfn m\u1edbi, m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u1ea1t \u0111\u01b0\u1ee3c hi\u1ec7u su\u1ea5t v\u01b0\u1ee3t tr\u1ed9i h\u01a1n so v\u1edbi c\u00e1c' metadata={'source': '/content/YOLOv10_Tutorials.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Number of sub-documents: \", len(docs))\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "7ab4a6eb8fe94e24b15f242c97ec0aef",
      "927f9b69c8a04e6bb7d9e6d4e4fb9b4b",
      "0196f5b1e3dc41e9b8659a40658bc539",
      "613e2d8916cf4b638600abb20172b4c2",
      "f6070446ed724eb69f3da64516d078ba",
      "bf59d741ffc743c2910dc1f6635a923d",
      "5236ca2a2d774fa29bfcae83924c6423",
      "9a94f33fd5ec4fc092022762834d5f4b",
      "2b287f6d479146259b79283ac5c01c3c",
      "c3be789efc504b969549a9a467728c58",
      "c89ac522925b4a9488cb1fafa0410bef",
      "754a54b17c0c4570b0abbf51eb8d2b4b",
      "428e5e4e99944d5cb5b69fc3d021293d",
      "ef9c7d6d703d42fcb958c832e784b59c",
      "27393bf7402d45378667c074f6de07a1",
      "a570a9f139e04ea78e70242f07773923",
      "666e8a842e664e2988e69a8f3301ca59",
      "0e352a9db90d4d308be570e03aaf4fc6",
      "e65b3f3b4ddc444e8097b6441ea15112",
      "93778122a2534cd99def9a82b5a2b65b",
      "f2ac60ffd8a0435c853c2ab003ef917f",
      "301bb1493c30463e8cc2d53793ab6172",
      "7af68b445f334a548a1a581f5812ba38",
      "164916e0d996473484f6177e3e976ef1",
      "34e9925ba3944bedb6c87c15fe61cf3f",
      "52e04230964045db938a9c7345982f0c",
      "1e0d0fee75ce40f799421ed06b9c33d5",
      "6afc47c0f31e4cbdb2ddc6ce31b74b64",
      "2b8a7d16771044f6aeaf83b0d6bd61a8",
      "e8e3ad5fdbac40a3ae19a4ac3cdae21e",
      "062b5f330a9c4114a149a3fd4df7305f",
      "eb334cf3f2d04575afcaaec001ecf317",
      "17282b234d194b99b8e6d68c37b8b670",
      "7e6227113c5e401bb9e63b827c4c144c",
      "f35ec85f56c445b49eabc21400976224",
      "ec4c64637b644a6c986dca89469b6229",
      "5e824a7a2ad44a758b294661f327c103",
      "1285ccb2b60c4d329b3c934be2828b5c",
      "b6491e6ecf1b4bdf9c67df05fb101c52",
      "c1c72d93c3674242915445646778c10e",
      "63ea176afce64d3994458ff04dc77f65",
      "8646dedcee6c41c8a98753ba1208f1e3",
      "4b70a872a94146709ca9ab630dfdc8b4",
      "5b784fe53d164144abe9a435fb0c8e74",
      "23c60f09edf64d7e9886017c923c53c9",
      "5f224e8c14454c43820569912f10b95e",
      "fac1343cb8a24683bae4f69bcf2303cc",
      "d3343f8864484985a4ec0774fe7f2145",
      "228a4c3ab7604fd9ab39a921fe85c5bf",
      "1033ddc50eb14c1391cbab61fa4ff583",
      "8f7c2d02e11f4265a5aa1a8eae9854ba",
      "dfc9851f12bf4a1faee58e8b57636d02",
      "c442bdb891fc4241a992eb04fe3a75ed",
      "a470682f41264da592775fe0e758ce38",
      "6993cfab144b496193f1b873235affcd",
      "f9fa22a1725847a296ac935188f4ebe9",
      "0dbb10875ef14051a2cc6216f18f231e",
      "59f40d9d4f2b453f938a3dff025f847c",
      "b90b4dd13dae4283b66cbb33dd2ef458",
      "bc1f4086437f4bf79e3c072abf030183",
      "b8978c5656c5458ba914ff29b1c928ae",
      "0598f73f1f0f4f77a8d2e6fe42e424fb",
      "fd0b058836ba407cbb4515d7aecb6fc5",
      "06977ec083494e2b8a105c02930c895f",
      "4f07fee9b6c443308027d68df99b5411",
      "4f8393e2d4c5483b8e7f4a79dfbc1d59",
      "95a1d6174975433f9dbfd94ba81dee8f",
      "b2250ae21c54492095796305051f0fee",
      "07d8ad8b30344131a0663be0784410a2",
      "dc83b1c383de45ff8ccb8f2f8b3c021d",
      "a2e2656e1d4840faaad5f702bd05c6f1",
      "b7520a3fd61046ffa13382317076b2f2",
      "0d83ab8a1e274ceba1cc55196204d8b3",
      "b46101ce8c9847469b709e817dc68390",
      "c85a8fc24b7d4e3ea3d581e38b8f8103",
      "779c09b099264518803a889af479cbd2",
      "939ab57af9be4f32a37c4d0bc72e4966",
      "a8ef74a527844069863dadc5dfbc943a",
      "ba8b3760bcf24582b87ad5ab86a5bb2e",
      "6c9a2f6d41914b04979a8d7ec2829806",
      "6eb3172785d241458c7419a2014389fc",
      "f1e73a6244b64de7aa59375e34435db2",
      "3b1632c7d0014ac8a0ab1fb3e1fac734",
      "1f6d2073f51245d9bfe90679cdf45632",
      "3dd6eb60e8294f4bb4e7a1bfcd25d680",
      "0408b2e04445401a84c71aac73d0702d",
      "a482f467f4884532ace8b1858c08ffaf",
      "6107fc9121e44086afb393aac6919023",
      "9a160abdc1b44e7aaf47a39993ab780f",
      "e47d218cb9ab45bcb7209c09738a651e",
      "830c78b8d51e47d380af8a8a2921b6df",
      "0de2fb31b36545cf9d38a8043a45e7f2",
      "2630c7ab769945ea8a0e738dfef2dd01",
      "fa10bcfcfac6402e927e821c003dc6ed",
      "6673e42b64604c308bebd23051619b2c",
      "36510e8ba3a9453da83cd84a1d45c77f",
      "ab8c0e81a3314ddc860619a8a2b0e0dd",
      "091c88a5bc554370a69827a6bf320f44",
      "065a2aa94d474fb7b0d6f9a64a203f00",
      "8c27f79e7f3b4948a101f0b8db55491a",
      "36da10093e31439dbc20ea477cbc831f",
      "b22c7205478748f592e965d23b2eab7e",
      "67fd49ad27364537ab8263d648c6498d",
      "5424d8a1f4d6474c938989c3179594a0",
      "cc90d761f3624d2b8959509300baf390",
      "70c0bf37b3c84ad185c2010ca4d9557e",
      "3d49094e98f04890a924fdc69de97b0b",
      "87f81c709cc843d79c7f4060be54640c",
      "7bdddcc1e7634f72882ce30422c7f18b",
      "21f5895521b244a492689e9b22a56aad",
      "5b6fc081c9964e539148cd047c0dab75",
      "23cab5cf6cdf46f292262b737327e515",
      "18836c45b61e4701a57703583cd972f6",
      "6f94c1279d374213b8337d4186ceb115",
      "0e8120ea644245eba9da21972455d901",
      "fc26ef8549ad4a0bb3089b8fdacad189",
      "b91338d1118b45f7bba48608219cb01a",
      "1a39afabb5bc441c8256e5e875c9bdb0",
      "a99c8c15b1a948cd9750f12a756743d0",
      "89a107d0d8c34aa19fc843a0b4fd057e",
      "da07025ed70448878958977380630f1b"
     ]
    },
    "id": "7zmUCt13aZYg",
    "outputId": "0debe318-a02a-4b0f-f7d7-2a749f1db687"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab4a6eb8fe94e24b15f242c97ec0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754a54b17c0c4570b0abbf51eb8d2b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af68b445f334a548a1a581f5812ba38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6227113c5e401bb9e63b827c4c144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c60f09edf64d7e9886017c923c53c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fa22a1725847a296ac935188f4ebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a1d6174975433f9dbfd94ba81dee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ef74a527844069863dadc5dfbc943a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a160abdc1b44e7aaf47a39993ab780f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c27f79e7f3b4948a101f0b8db55491a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6fc081c9964e539148cd047c0dab75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create instance vectorization\n",
    "embedding = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIsRClf9amZS",
    "outputId": "174f9173-c4c4-4b5b-d182-30d6b4c2ff06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant documents:  4\n"
     ]
    }
   ],
   "source": [
    "# Create vector database\n",
    "vector_db = Chroma.from_documents(documents=docs, embedding=embedding)\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "result = retriever.invoke(\"What is YOLO?\")\n",
    "print(\"Number of relevant documents: \", len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85xDV5vwbfPw"
   },
   "source": [
    "## 3. Create Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xgoh353-bt4c"
   },
   "outputs": [],
   "source": [
    "# Some installation\n",
    "nf4_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "3be2b26ed94c4a56a1aecdf3b647176e",
      "2ac8034861a34cf6a55ccde86aae0dd4",
      "b23a56566e8e490abd997729c7107b65",
      "d9df991f17df47fdaf31d0818894af1b",
      "c8797e81fa514e15904660c530f8e67d",
      "5c38d52f4f5b41ecafd645be47049dec",
      "6d1d77be069b4983a4ffc6dbba47ac50",
      "060e578109dc4f64a4ac88f78e156993",
      "276263c6837840298271588b9dea26de",
      "3f6df1210720474680f30bc81c961736",
      "a20d3c8357634299b5fdd884a8b32879",
      "c355585581284d7bb7f171fb3fcee3b5",
      "856e6ebc139c49d196316a6afabd2b17",
      "f0a547c68b5b4ecbb369ef7cc8cacb4f",
      "1295a09b97de494b9e747d4e02c326af",
      "18a4be8fbdae4828b8924f7d53b79986",
      "dad0b77cc8a44adc9f2b59b83e7484e2",
      "4a057ef721614c0997124c9c1740f161",
      "2a30bb19c38b4e07a842534eae0b3443",
      "c089e3f5d09242e58d8d5b641a6d3551",
      "78c5e18cb7bd4ec5bffe5168a70021d9",
      "1540dca2f52d4dddb349d3d1914728d7",
      "87f329c15b3b48a3addef359db12e123",
      "b457d017e44d486fa078f7a842328623",
      "099a01d60b694e9b9681074410cbd89f",
      "52a34d5e8cd44ab98a80017c39021abc",
      "883849999b3b4b4782f20ad3584600c2",
      "20cbdbeb80ea4450a6d0cca3a8ff6e1e",
      "b8f95c7835114106b62829ea1b10f1e1",
      "e493fd60d33b430dab20766d5e5adf5f",
      "a36da16798904949820420bd6e04c4b5",
      "1917990447b0461eb8b6bedea4ef561d",
      "3cd4af66aa53408d91af9360e2336096",
      "33f99a2cd5c6457e9a8a858f038496c4",
      "f07274b3472a48d8af2da6fb25215cd1",
      "e9e7543328904884ac207b32bcaba2e1",
      "b45b85c475be4b40bc291da79a3000e7",
      "7e7005e5894b43f3975f4a8290b6099b",
      "f88ad94bc3444b068be62a6f9391fe58",
      "0c8051ac28df41ae916ae8bae5a5cfac",
      "5772cc90d3e845c68e10cef0525937ba",
      "2feeedb19ea64d788b31c6c1fb6bb653",
      "e6185500685c43dfbfd0959fada209ed",
      "9274d8ebc36b46768bcdf3025584379c",
      "7e5228ffc7c24f8f971abbed2369ec53",
      "f5abbf42ca514cb288f7319714b9557e",
      "e4e7d16476cc4184a247fbbd8285b995",
      "59378d2b450340538bbf83333ef2ba78",
      "8ae08c6652c542e98d6e6aa0070893b7",
      "cb074fc1825c4bc2b4a8ad580306ab27",
      "865cb587742e406283d237c00d2ff8c7",
      "228f4ffd5e26439488bdc5609937d5cf",
      "e12f46c7157748ffa3950a2e1d4d3a9e",
      "3e75fa77e275437da8181b7ed958830a",
      "8e4445b892a24e2babfa68e3f1f42d6c",
      "f7a9d32a8d2c4c01bf313021ef039a77",
      "c081b7280e65454ca24c57bec660f972",
      "26662e33f66f405b891b72c6eda2ce00",
      "58c2ecfa13934591b014d01fac36a78b",
      "9d89ed84dda946138557aea1eaa1f928",
      "64acaecc42a944bb8b239ea60f8cc99e",
      "89295d67017f4eef8e27558ccd29cbd3",
      "3ad0c1a4e4f149a781c8336a31b50cb6",
      "f685e18c7425435c962b7a3516d20b8c",
      "977d959f2c0446d4afd8900575df689c",
      "928d72182e734899a34a054f191c388e",
      "0dce7b55bc3f484684e377c177ef0656",
      "b8d2a1c74f1d46bdb62629563e7cda2f",
      "05c813efe3e64999906e54aacec8db22",
      "8f180d5498584f84affc49c34092f0d3",
      "372726f1027e47c2bb8b9ebeeae8559b",
      "2dc9928406ee499e9de3d88eec6814ca",
      "33b7f219a365472f87e43f76b3d97c80",
      "1951eb588af44412ab1bec0502f6cfd1",
      "61a59443dd884da9b933c690233bd5e4",
      "0462911c8925411ebb2067f713271469",
      "fbcecbad59a94d23ad4bf1fabb3c47e9",
      "3f927fbee5464f1d879595bf8d3f47dc",
      "32d2809afb6a400cbdd02b22086fe7d2",
      "c1023bb75ffd4d2f874453d5c0563bf8",
      "d778852dbddd4d9089117043eae87558",
      "490ddef2beae4dcca15875b1949413ec",
      "8b46867f30dc4b28a78b3d9623b62261",
      "c9c91ccbec1d44acb9c5776e5ffa7522",
      "d42eafa5d4b34c4da469f9117b299721",
      "3a3b4ec653d340a880375a009ae1338c",
      "aeb233a895164f04bf8e0387ddb20249",
      "e26841dec3414042adbbec779e5cb255"
     ]
    },
    "id": "CopxXD8Bb5PQ",
    "outputId": "b6235a5e-af6c-4843-f945-6429d68ddbed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be2b26ed94c4a56a1aecdf3b647176e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c355585581284d7bb7f171fb3fcee3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:  24%|##3       | 2.38G/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f329c15b3b48a3addef359db12e123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f99a2cd5c6457e9a8a858f038496c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5228ffc7c24f8f971abbed2369ec53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a9d32a8d2c4c01bf313021ef039a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dce7b55bc3f484684e377c177ef0656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f927fbee5464f1d879595bf8d3f47dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create model and tokenizer:\n",
    "MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, quantization_config=nf4_config, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRfUXa6bcOSt"
   },
   "outputs": [],
   "source": [
    "# Use pipeline for model and tokenizer\n",
    "model_pipeline = pipeline(\"text-generation\",\n",
    "                          model=model,\n",
    "                          tokenizer=tokenizer,\n",
    "                          max_new_tokens=512,\n",
    "                          pad_token_id=tokenizer.eos_token_id,\n",
    "                          device_map=\"auto\")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=model_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jxb24BagcrGq",
    "outputId": "fdeaf42f-eb3c-46c8-fb01-5f76bd596851"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv10 l\u00e0 m\u1ed9t phi\u00ean b\u1ea3n c\u1ee7a YOLO (You Only Look Once) - m\u1ed9t h\u1ec7 th\u1ed1ng d\u1ef1 \u0111o\u00e1n h\u00ecnh \u1ea3nh \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n s\u1eb5n tr\u00ean b\u1ed9 d\u1eef li\u1ec7u COCO. Phi\u00ean b\u1ea3n n\u00e0y \u0111\u01b0\u1ee3c t\u1ea1o b\u1eb1ng c\u00e1ch t\u1ea3i v\u1ec1 tr\u1ecdng s\u1ed1 (file.pt) t\u1eeb GitHub v\u00e0 kh\u1edfi t\u1ea1o m\u00f4 h\u00ecnh b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng th\u01b0 vi\u1ec7n ultralytics.\n"
     ]
    }
   ],
   "source": [
    "# Run the program\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = ({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser())\n",
    "\n",
    "USER_QUESTION = \"YOLOv10 l\u00e0 g\u00ec?\"\n",
    "output = rag_chain.invoke(USER_QUESTION)\n",
    "answer = output.split(\"Answer:\")[1].strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yz3LF1U5eNcT"
   },
   "source": [
    "# RAG with Chainlit Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhVN2sW0eik5"
   },
   "source": [
    "## 1. Install some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PbUfG2vedZu",
    "outputId": "59a6728c-fccf-402c-97ed-61c41a0140d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n",
      "+ localtunnel@2.0.2\n",
      "added 22 packages from 22 contributors in 1.511s\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chainlit 1.1.304 requires numpy<2.0,>=1.26; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
      "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.41.2\n",
    "!pip install -q bitsandbytes==0.43.1\n",
    "!pip install -q accelerate==0.31.0\n",
    "!pip install -q langchain==0.2.5\n",
    "!pip install -q langchainhub==0.1.20\n",
    "!pip install -q langchain-chroma==0.1.1\n",
    "!pip install -q langchain-community==0.2.5\n",
    "!pip install -q langchain-openai==0.1.9\n",
    "!pip install -q langchain_huggingface==0.0.3\n",
    "!pip install -q chainlit==1.1.304\n",
    "!pip install -q python-dotenv==1.0.1\n",
    "!pip install -q pypdf==4.2.0\n",
    "!npm install -g localtunnel\n",
    "!pip install -q numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dyh3I_VHe2x4"
   },
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "import torch\n",
    "\n",
    "from chainlit.types import AskFileResponse\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSZW80_ehOpd"
   },
   "source": [
    "## 2. Create text splitter and instance vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLJx9ScxfNy5"
   },
   "outputs": [],
   "source": [
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# Create instance vectorization\n",
    "embedding = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgcWW4uUhXxR"
   },
   "source": [
    "## 3. Input processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKTIjBJSfaD8"
   },
   "outputs": [],
   "source": [
    "# Write a function for input processing\n",
    "def process_file(file: AskFileResponse):\n",
    "    if file.type == \"text/plain\":\n",
    "        Loader = TextLoader\n",
    "    elif file.type == \"application/pdf\":\n",
    "        Loader = PyPDFLoader\n",
    "\n",
    "    loader = Loader(file.path)\n",
    "    documents = loader.load()\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc.metadata[\"source\"] = f\"source_{i}\"\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8dZ_BAVhcq9"
   },
   "source": [
    "## 4. Chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMLUg9KXf6w9"
   },
   "outputs": [],
   "source": [
    "# Write a function for Chroma database:\n",
    "def get_vector_db(file: AskFileResponse):\n",
    "    docs = process_file(file)\n",
    "    cl.user_session.set(\"docs\", docs)\n",
    "    vector_db = Chroma.from_documents(documents=docs, embedding=embedding)\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HbiofR9hgxq"
   },
   "source": [
    "## 5. Create Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496,
     "referenced_widgets": [
      "bf994be772f94c02aa817ba48c008e19",
      "a75bab62fad44794a1bf7138000a2108",
      "ad28596cd3c542fc8c9530a7185565cf",
      "5384b215c46d4beaa8d62e55751f6c56",
      "1af58584ffd0482ebe41f9b95b205ba6",
      "2780a3913119472f84f88b797351cd70",
      "1b4d2ace62144635bf6299d59139fe8a",
      "20e87cbc453d463b9841a6109fa74f04",
      "c260cd3142454df889e1efd958d005ee",
      "16a551c90d41490b9a216dcad691ec9c",
      "08b67c181dca4773a5953c190c97cbc4",
      "6e39ff88277342cfb4a411473d8eb362",
      "41397b4117c94fbfa594108e8407ca17",
      "50631f021e9247e695fd4f95426085ed",
      "009c6c7bc85b491cb74bcd1e9ed96a3f",
      "0c303ed554de4672959691f55bffc999",
      "4398f1863a8c43d78d6a084e5de6da9c",
      "d2031bac99e9495a89c45a35b866e7c9",
      "95bed016850146d69d87cbc15aa7e3b0",
      "819bf1083ad04cf49222765cb050b4bc",
      "1eaeea45307a49b7aca37d3c915c2d5c",
      "324a8d9ec9c4476698ce49075ce60e5b",
      "615405162fa0437786a9212f2f66c9a4",
      "d7a48da7e39a4c48a069ee1f933d94b8",
      "7c5cc9ffc14249b2944186b130930f02",
      "cd87e0b23ccf4f5481ede41ff57a6f63",
      "f40b544f5b4a4b0ebc44289e9cd55cc8",
      "3a957adf14fe41feb12938310a37c227",
      "702c885a0bb145699482fe04a67b4cd7",
      "a9171a0fcfb84a36a0a33c5ad7c00282",
      "feec4148d2294fd6a55adeda7747006e",
      "3b795ada4fb54619906304c8aef0df30",
      "53502398ce1e4f21912581eef5908015",
      "fdd8bc0f27f7455ea78fad5e5e47b8a3",
      "aa76e89d182f49bea3419c11d76fff95",
      "c0138fe3649344af9732a76431561277",
      "ae841fd07b654223baec14892296c68a",
      "890d266de1724188a4958407740e2d84",
      "b0f7232593ea409cbaf8df565e755708",
      "995b045ea7b84d38acfe53fcf79432bd",
      "21f8359a19b94c48a94ab55366556944",
      "e7cbaa574e7143309276f65436928204",
      "9038b2f8af844403b31b5635ea537aca",
      "d1c87e8ec36547caa0963ba2436dcdc1",
      "d18770b34a7f4b10b3cae425493b01f0",
      "a27e9af3963245499782aca0d9a2cad1",
      "723da0983b2544d3adf78ebb32e84ba5",
      "fd2c9edacfaf4997b31d382c5869e10e",
      "04626eef507c4f1a97e18b871b6eb1f0",
      "2732af08f21e4678afee71ae9c7a4ee9",
      "78fbe4350c384d35a76c95b7bdc75da3",
      "c698f55318f54c61b326109200afb605",
      "1260f803cdaf46ae95a1bd09ec29b5a5",
      "e7ebd05a1eb547f197efea1992211189",
      "83a0706dbcd8477ca6b46e0d0fd01ad8",
      "7f06f4055a8a4d0cbbd3da5efa6cb301",
      "ed8f2f157f4145bf80b5271b27561c93",
      "5d04f2778c6d44b8806bcb656a883185",
      "6de71260b0714846b515834dc808b894",
      "be921b5091c340f993de25f7bf95f52a",
      "db5dd6c47d3a46c59582c8734ac02dbe",
      "0cf158b7614349fca46472aa2d94e85f",
      "882d668d7594491da9b3b439f4371ba5",
      "da436f2f39fd40c38c0af1405a555c30",
      "431464b520944f318cbee8d3369f11ec",
      "66c35dd619ed4493bac9026f6f564978",
      "2e903c6341fb40f2bc225fde704c0f1e",
      "a53d426aa2f9456ab0c548db2b24ac38",
      "22d3092026524690ba99585defacf988",
      "ec3f8d640dad441e885df1c6434fedcc",
      "cc363dcf2bb54fc3b5b4a5954dfffabd",
      "4ed79b963c5f42a5afcf88f8e1bcbbb4",
      "8abfe1befe9144c2bc187b8a26f653ce",
      "c382573efe5546d49a6e0aa050851445",
      "1df5a75c94b047028bd651075d6730ad",
      "1587494c2f0747f3a75174c00bfeb427",
      "dfd92662b5864b6ba93f66c8acb5962d",
      "6bc8fddd6df8410ca54ef921085014f8",
      "26f0a1b1c502484191d53c064691e52d",
      "132fe74b38a54888a3c52956a5b31988",
      "e468ce54f1b74843918396a2f4c23079",
      "1dcdf08a73d9469abe9859362d3331b7",
      "274b9183f51845fda49d5f87976318a9",
      "dbf3301dabcd4ec69d3344f3627fe2d1",
      "6e7d02d360d342b3907cbd72334765d3",
      "a55f2037fffe4bf186a76ed0ec320d58",
      "a3cdd61ac3524e1fbe5ddb2f1cb6d57b",
      "19ff03df7fc745ae930492f6b54d1554",
      "5abbea2122c94815a0366597f7f5556a",
      "5e3d7f39f94b47ca8bb7bc42025abfc1",
      "009018965d23478b8fbfb663c94f019d",
      "cf7162a8d47b45898b3e8782fa064644",
      "80fb6e6c986c4bb2a267a3b94c255e13",
      "fd26af6da7bc483cbda3690bf8dbbe22",
      "b7a6e0ff37304dc1be65e1fc3e1174c0",
      "b71b5ad27a3249fa9f01f94c8aa16590",
      "960f59e868bc4f7ea0b2ceb84de844ae",
      "137556abcb4746b68f7769d549aa3411",
      "e19330e84b364cea98ae21b06d09a20f",
      "d012376b40e141f2848430ad66fc053e",
      "6925ac5cc1ca4155b110a5240f6a653b",
      "f13cd498516a4ed28e3c75569900a68d",
      "d0412bcc65384a2ba7d24d811fdaecc9",
      "8208060755b64d94a68d8f65cbb9950d",
      "1cc5a50aba3145e886ebdaae30f4904c",
      "03c89f898b8b498280579a301193ee79",
      "6db86f8217d3499aa00ca581d6b4ce9c",
      "5f6772203c2a455cb4d721f912af83dc",
      "b6b8eab62ae34592821246aed97862db",
      "cc516b8f95ab41ce8e767d0471c932de"
     ]
    },
    "id": "JdPzV4pJgPoR",
    "outputId": "9a76eee1-3817-42d6-851e-52ac24d8dbf1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf994be772f94c02aa817ba48c008e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e39ff88277342cfb4a411473d8eb362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615405162fa0437786a9212f2f66c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd8bc0f27f7455ea78fad5e5e47b8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18770b34a7f4b10b3cae425493b01f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f06f4055a8a4d0cbbd3da5efa6cb301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e903c6341fb40f2bc225fde704c0f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc8fddd6df8410ca54ef921085014f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abbea2122c94815a0366597f7f5556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d012376b40e141f2848430ad66fc053e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_huggingface_llm(model_name: str=\"lmsys/vicuna-7b-v1.5\", max_new_token: int=512):\n",
    "\n",
    "    nf4_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                    bnb_4bit_quant_type=\"nf4\",\n",
    "                                    bnb_4bit_use_double_quant=True,\n",
    "                                    bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                quantization_config=nf4_config,\n",
    "                                                low_cpu_mem_usage=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model_pipeline = pipeline(\"text-generation\",\n",
    "                              model=model,\n",
    "                              tokenizer=tokenizer,\n",
    "                              max_new_tokens=max_new_token,\n",
    "                              pad_token_id=tokenizer.eos_token_id,\n",
    "                              device_map=\"auto\")\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=model_pipeline)\n",
    "    return llm\n",
    "\n",
    "LLM = get_huggingface_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBFDKa07hutD"
   },
   "source": [
    "## 6. Create welcome message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVqEAvLihJ-c"
   },
   "outputs": [],
   "source": [
    "welcome_message = \"\"\"Welcome to the PDF QA! To get started:\n",
    "1. Upload a PDF or text file\n",
    "2. Ask a question about the file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ghn7XNGrjJgb"
   },
   "source": [
    "## 7. Create on_chat_start function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8O_20PyShybL"
   },
   "outputs": [],
   "source": [
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    files = None\n",
    "    while files is None :\n",
    "        files = await cl.AskFileMessage(content=welcome_message,\n",
    "                                        accept =[\"text/plain\", \"application/pdf\"],\n",
    "                                        max_size_mb=20,\n",
    "                                        timeout=180).send()\n",
    "    file = files[0]\n",
    "\n",
    "    msg = cl.Message(content=f\"Processing '{file.name}'...\",\n",
    "                     disable_feedback=True)\n",
    "    await msg.send()\n",
    "\n",
    "    vector_db = await cl.make_async(get_vector_db)(file)\n",
    "\n",
    "    message_history = ChatMessageHistory()\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "                                      output_key =\"answer\",\n",
    "                                      chat_memory=message_history,\n",
    "                                      return_messages=True)\n",
    "    retriever = vector_db.as_retriever(search_type=\"mmr\",\n",
    "                                       search_kwargs={\"k\":3})\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm=LLM,\n",
    "                                                  chain_type=\"stuff\",\n",
    "                                                  retriever=retriever,\n",
    "                                                  memory=memory,\n",
    "                                                  return_source_documents=True)\n",
    "\n",
    "    msg.content = f\"'{file.name}' processed. You can now ask questions!\"\n",
    "    await msg.update()\n",
    "\n",
    "    cl.user_session.set(\"chain\", chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSHeUM5ykN_q"
   },
   "source": [
    "## 8. Create on_message function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faRt6wOcjPq8"
   },
   "outputs": [],
   "source": [
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "    chain = cl.user_session.get(\"chain\")\n",
    "    cb = cl.AsyncLangchainCallbackHandler()\n",
    "    res = await chain.ainvoke(message.content, callbacks=[cb])\n",
    "    answer = res[\"answer\"]\n",
    "    source_documents = res[\"source_documents\"]\n",
    "    text_elements = []\n",
    "\n",
    "    if source_documents :\n",
    "        for source_idx, source_doc in enumerate(source_documents):\n",
    "            source_name = f\"source_{source_idx}\"\n",
    "            text_elements.append(cl.Text(content=source_doc.page_content,\n",
    "                                         name=source_name))\n",
    "        source_names = [text_el.name for text_el in text_elements]\n",
    "\n",
    "        if source_names:\n",
    "            answer += f\"\\nSources: {', '.join(source_names)}\"\n",
    "        else:\n",
    "            answer += \"\\nNo sources found \"\n",
    "\n",
    "    await cl.Message(content=answer, elements=text_elements).send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxwJjnnWkTQp"
   },
   "source": [
    "## 9. Run chainlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLNFwaY9kYbw"
   },
   "outputs": [],
   "source": [
    "!chainlit run app.py --host 0.0.0.0 --port 8000 &>/content/logs.txt &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrIHC5gJkejN"
   },
   "source": [
    "## 10. Expose localhost into public host by localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcH3l5c24fAW"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "print(\"Password/Enpoint IP for localtunnel is:\", urllib.request.urlopen(\"https://ipv4.icanhazip.com\").read().decode(\"utf8\").strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twAXc9Ku4gLe"
   },
   "outputs": [],
   "source": [
    "!lt --port 8000 --subdomain aivn-simple-rag"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}